# pix2gestalt: Amodal Segmentation by Synthesizing Wholes
### In Submission
### [Project Page](https://gestalt.cs.columbia.edu/)  | [Paper](https://arxiv.org/pdf/2401.14398.pdf) | [arXiv](https://arxiv.org/abs/2401.14398) | [Weights](https://huggingface.co/cvlab/pix2gestalt-weights)

[pix2gestalt: Amodal Segmentation by Synthesizing Wholes](https://gestalt.cs.columbia.edu/)  
 [Ege Ozguroglu](https://egeozguroglu.github.io/)<sup>1</sup>, [Ruoshi Liu](https://ruoshiliu.github.io/)<sup>1</sup>, [Dídac Surís](https://www.didacsuris.com/)<sup>1</sup>, [Dian Chen](https://scholar.google.com/citations?user=zdAyna8AAAAJ&hl=en)<sup>2</sup>, [Achal Dave](https://www.achaldave.com/)<sup>2</sup>, [Pavel Tokmakov](https://pvtokmakov.github.io/home/)<sup>2</sup>, [Carl Vondrick](https://www.cs.columbia.edu/~vondrick/)<sup>1</sup> <br>
 <sup>1</sup>Columbia University, <sup>2</sup>Toyota Research Institute


![teaser](./assets/teaser.gif "Teaser")

## Updates
- Our paper is now available on [arXiv](https://arxiv.org/abs/2401.14398)! 
- Pre-trained weights and preliminary Gradio demo coming soon.
- Stay tuned for the release of our training & inference scripts!

## Citation
If you use this code, please consider citing the paper as:
```
@misc{ozguroglu2024pix2gestalt,
      title={pix2gestalt: Amodal Segmentation by Synthesizing Wholes}, 
      author={Ege Ozguroglu and Ruoshi Liu and Dídac Surís and Dian Chen and Achal Dave and Pavel Tokmakov and Carl Vondrick},
      year={2024},
      eprint={2401.14398},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

##  Acknowledgement
This research is based on work partially supported by the Toyota Research Institute, the DARPA MCS program under Federal Agreement No. N660011924032, the NSF NRI Award \#1925157, and the NSF AI Institute for Artificial and Natural Intelligence Award \#2229929. DS is supported by the Microsoft PhD Fellowship.
